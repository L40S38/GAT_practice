{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous Graph Learning\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/heterogeneous.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colabでやるならこっち\n",
    "#os.environ['TORCH'] = torch.__version__\n",
    "#print(torch.__version__)\n",
    "\n",
    "#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "#!pip install graphviz\n",
    "#!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ローカルのcondaでやるならこっち\n",
    "#%conda install python==3.10.6\n",
    "#%conda install -c conda-forge matplotlib -y\n",
    "#%conda install -c pytorch pytorch torchaudio torchvision -y\n",
    "#%conda install -c pytorch pytorch torchvision torchaudio -y\n",
    "#%conda install -c anaconda networkx -y\n",
    "#%conda install -c conda-forge python-graphviz -y\n",
    "#%conda install -c conda-forge graphviz -y\n",
    "#%pip install torchviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#%pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#%pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch_geometric #上のセルでうまくいかない場合は拡張パッケージのインストールはあきらめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeteroDataの概要\n",
    "![](https://pytorch-geometric.readthedocs.io/en/latest/_images/hg_example.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    x=[736389, 128],\n",
       "    year=[736389],\n",
       "    y=[736389],\n",
       "    train_mask=[736389],\n",
       "    val_mask=[736389],\n",
       "    test_mask=[736389],\n",
       "  },\n",
       "  author={ x=[1134649, 128] },\n",
       "  institution={ x=[8740, 128] },\n",
       "  field_of_study={ x=[59965, 128] },\n",
       "  (author, affiliated_with, institution)={ edge_index=[2, 1043998] },\n",
       "  (author, writes, paper)={ edge_index=[2, 7145660] },\n",
       "  (paper, cites, paper)={ edge_index=[2, 5416271] },\n",
       "  (paper, has_topic, field_of_study)={ edge_index=[2, 7505078] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もしオリジナルのデータセットを構成する場合は以下のように書いていく\n",
    "```python\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['paper'].x = ... # [num_papers, num_features_paper]\n",
    "data['author'].x = ... # [num_authors, num_features_author]\n",
    "data['institution'].x = ... # [num_institutions, num_features_institution]\n",
    "data['field_of_study'].x = ... # [num_field, num_features_field]\n",
    "\n",
    "data['paper', 'cites', 'paper'].edge_index = ... # [2, num_edges_cites]\n",
    "data['author', 'writes', 'paper'].edge_index = ... # [2, num_edges_writes]\n",
    "data['author', 'affiliated_with', 'institution'].edge_index = ... # [2, num_edges_affiliated]\n",
    "data['paper', 'has_topic', 'field_of_study'].edge_index = ... # [2, num_edges_topic]\n",
    "\n",
    "data['paper', 'cites', 'paper'].edge_attr = ... # [num_edges_cites, num_features_cites]\n",
    "data['author', 'writes', 'paper'].edge_attr = ... # [num_edges_writes, num_features_writes]\n",
    "data['author', 'affiliated_with', 'institution'].edge_attr = ... # [num_edges_affiliated, num_features_affiliated]\n",
    "data['paper', 'has_topic', 'field_of_study'].edge_attr = ... # [num_edges_topic, num_features_topic]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_node_data = data['paper']\n",
    "cites_edge_data = data['paper', 'cites', 'paper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': tensor([[-0.0954,  0.0408, -0.2109,  ...,  0.0616, -0.0277, -0.1338],\n",
       "         [-0.1510, -0.1073, -0.2220,  ...,  0.3458, -0.0277, -0.2185],\n",
       "         [-0.1148, -0.1760, -0.2606,  ...,  0.1731, -0.1564, -0.2780],\n",
       "         ...,\n",
       "         [ 0.0228, -0.0865,  0.0981,  ..., -0.0547, -0.2077, -0.2305],\n",
       "         [-0.2891, -0.2029, -0.1525,  ...,  0.1042,  0.2041, -0.3528],\n",
       "         [-0.0890, -0.0348, -0.2642,  ...,  0.2601, -0.0875, -0.5171]]), 'year': tensor([2015, 2012, 2012,  ..., 2016, 2017, 2014]), 'y': tensor([246, 131, 189,  ..., 266, 289,   1]), 'train_mask': tensor([True, True, True,  ..., True, True, True]), 'val_mask': tensor([False, False, False,  ..., False, False, False]), 'test_mask': tensor([False, False, False,  ..., False, False, False])},\n",
       " {'edge_index': tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
       "         [    88,  27449, 121051,  ..., 421711, 427339, 439864]])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_node_data,cites_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_index': tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
      "        [    88,  27449, 121051,  ..., 421711, 427339, 439864]])}\n",
      "{'edge_index': tensor([[     0,      0,      0,  ..., 736388, 736388, 736388],\n",
      "        [    88,  27449, 121051,  ..., 421711, 427339, 439864]])}\n"
     ]
    }
   ],
   "source": [
    "cites_edge_data = data['paper', 'paper']\n",
    "print(cites_edge_data)\n",
    "cites_edge_data = data['cites']\n",
    "print(cites_edge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新しいノードを増やしたり減らしたりする場合\n",
    "```python\n",
    "data['paper'].year = ...    # Setting a new paper attribute\n",
    "del data['field_of_study']  # Deleting 'field_of_study' node type\n",
    "del data['has_topic']       # Deleting 'has_topic' edge type\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper', 'author', 'institution', 'field_of_study']\n",
      "[('author', 'affiliated_with', 'institution'), ('author', 'writes', 'paper'), ('paper', 'cites', 'paper'), ('paper', 'has_topic', 'field_of_study')]\n"
     ]
    }
   ],
   "source": [
    "# メタデータへのアクセス\n",
    "node_types, edge_types = data.metadata()\n",
    "print(node_types)\n",
    "print(edge_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**A**,**B**,**C**)なら、**A**が**C**を**B**したということを示している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.has_isolated_nodes() #孤立しているノードの有無"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.has_self_loops() #セルフループの有無"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected() #接続しているノードの有無"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterogeneous Graph Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    x=[736389, 128],\n",
       "    year=[736389],\n",
       "    y=[736389],\n",
       "    train_mask=[736389],\n",
       "    val_mask=[736389],\n",
       "    test_mask=[736389],\n",
       "  },\n",
       "  author={ x=[1134649, 128] },\n",
       "  institution={ x=[8740, 128] },\n",
       "  field_of_study={ x=[59965, 128] },\n",
       "  (author, affiliated_with, institution)={ edge_index=[2, 1043998] },\n",
       "  (author, writes, paper)={ edge_index=[2, 7145660] },\n",
       "  (paper, cites, paper)={ edge_index=[2, 11529061] },\n",
       "  (paper, has_topic, field_of_study)={ edge_index=[2, 7505078] },\n",
       "  (institution, rev_affiliated_with, author)={ edge_index=[2, 1043998] },\n",
       "  (paper, rev_writes, author)={ edge_index=[2, 7145660] },\n",
       "  (field_of_study, rev_has_topic, paper)={ edge_index=[2, 7505078] }\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "data = T.AddSelfLoops()(data)\n",
    "data = T.NormalizeFeatures()(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to construct Heterogeneous GNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically Converting GNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero\n",
    "\n",
    "model = GNN(hidden_channels=64, out_channels=dataset.num_classes)\n",
    "model = to_hetero(model, data.metadata(), aggr='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ModuleDict(\n",
       "    (author__affiliated_with__institution): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (author__writes__paper): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (paper__cites__paper): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (paper__has_topic__field_of_study): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (institution__rev_affiliated_with__author): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (paper__rev_writes__author): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "    (field_of_study__rev_has_topic__paper): SAGEConv((-1, -1), 64, aggr=mean)\n",
       "  )\n",
       "  (conv2): ModuleDict(\n",
       "    (author__affiliated_with__institution): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "    (author__writes__paper): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "    (paper__cites__paper): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "    (paper__has_topic__field_of_study): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "    (institution__rev_affiliated_with__author): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "    (paper__rev_writes__author): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "    (field_of_study__rev_has_topic__paper): SAGEConv((-1, -1), 349, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch_geometric.nn.to_hetero()`もしくは`torch_geometric.nn.to_hetero_with_bases()`を使うとmetadataを基に勝手にheteroなモデルにしてくれる\n",
    "\n",
    "![](https://pytorch-geometric.readthedocs.io/en/latest/_images/to_hetero.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力特徴の数とテンソルのサイズはタイプによって異なるため、PyGは遅延初期化を利用して、heterogeneous GNNsのパラメーターを初期化できます (in_channels 引数として -1 で示されます)。\n",
    "\n",
    "これにより、計算グラフのすべてのテンソル サイズを計算して追跡する必要がなくなります。遅延初期化は、既存のすべての PyG 演算子でサポートされています。モデルのパラメータを 1 回呼び出すことで初期化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    mask = data['paper'].train_mask #valid, testのときはそれぞれ異なるmaskを用いる\n",
    "    loss = F.cross_entropy(out['paper'][mask], data['paper'].y[mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#多分こんな感じでTrainingすればよき\n",
    "#n_epoch = 5\n",
    "\n",
    "#for i in range(n_epoch):\n",
    "#    loss = train()\n",
    "#    print(f\"Epoch {i} Train Loss={loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Heterogeneous Convolution Wrapper\n",
    "\n",
    "`torch_geometric.nn.conv.HeteroConv` を使用すると、カスタム異種メッセージを定義し、異種グラフ用の任意の MP-GNN を最初から構築する関数を更新できます。自動コンバータ `to_hetero()` はすべてのエッジ タイプに同じ演算子を使用しますが、ラッパーでは異なるエッジ タイプに異なる演算子を定義できます。ここで、HeteroConv は、グラフ データ内のエッジ タイプごとに 1 つずつ、サブモジュールの辞書を入力として受け取ります。次の例は、それを適用する方法を示しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear\n",
    "\n",
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\n",
    "data = dataset[0]\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('paper', 'cites', 'paper'): GCNConv(-1, hidden_channels),\n",
    "                ('author', 'writes', 'paper'): SAGEConv((-1, -1), hidden_channels),\n",
    "                ('paper', 'rev_writes', 'author'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        return self.lin(x_dict['author'])\n",
    "\n",
    "model = HeteroGNN(hidden_channels=64, out_channels=dataset.num_classes, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "     out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Existing Heterogeneous Operators\n",
    "\n",
    "PyG provides operators (e.g., torch_geometric.nn.conv.HGTConv), which are specifically designed for heterogeneous graphs. These operators can be directly used to build heterogeneous GNN models as can be seen in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "\n",
    "dataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\n",
    "data = dataset[0]\n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in data.node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels) #node_typeごとに異なる次元 -> hidden_channels次元へ\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(),\n",
    "                           num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        return self.lin(x_dict['author'])\n",
    "\n",
    "model = HGT(hidden_channels=64, out_channels=dataset.num_classes, num_heads=2, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "     out = model(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterogeneous Graph Samplers\n",
    "\n",
    "PyG provides various functionalities for sampling heterogeneous graphs, i.e. in the standard torch_geometric.loader.NeighborLoader class or in dedicated heterogeneous graph samplers such as torch_geometric.loader.HGTLoader. This is especially useful for efficient representation learning on large heterogeneous graphs, where processing the full number of neighbors is too computationally expensive. Heterogeneous graph support for other samplers such as torch_geometric.loader.ClusterLoader or torch_geometric.loader.GraphSAINTLoader will be added soon. Overall, all heterogeneous graph loaders will produce a HeteroData object as output, holding a subset of the original data, and mainly differ in the way their sampling procedures works. As such, only minimal code changes are required to convert the training procedure from full-batch training to mini-batch training.\n",
    "\n",
    "Performing neighbor sampling using NeighborLoader works as outlined in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\hetero_graph_learning.ipynb Cell 42\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data \u001b[39m=\u001b[39m OGB_MAG(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m, preprocess\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmetapath2vec\u001b[39m\u001b[39m'\u001b[39m, transform\u001b[39m=\u001b[39mtransform)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_loader \u001b[39m=\u001b[39m NeighborLoader(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Sample 15 neighbors for each node and each edge type for 2 iterations:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     input_nodes\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m, data[\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtrain_mask),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/hetero_graph_learning.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch_geometric\\loader\\node_loader.py:134\u001b[0m, in \u001b[0;36mNodeLoader.collate_fn\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m input_data: NodeSamplerInput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_data[index]\n\u001b[1;32m--> 134\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_sampler\u001b[39m.\u001b[39;49msample_from_nodes(input_data)\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_per_worker:  \u001b[39m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:183\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_nodes\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_from_nodes\u001b[39m(\n\u001b[0;32m    180\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m     inputs: NodeSamplerInput,\n\u001b[0;32m    182\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[1;32m--> 183\u001b[0m     out \u001b[39m=\u001b[39m node_sample(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample)\n\u001b[0;32m    184\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubgraph_type \u001b[39m==\u001b[39m SubgraphType\u001b[39m.\u001b[39mbidirectional:\n\u001b[0;32m    185\u001b[0m         out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mto_bidirectional()\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:377\u001b[0m, in \u001b[0;36mnode_sample\u001b[1;34m(inputs, sample_fn)\u001b[0m\n\u001b[0;32m    374\u001b[0m     seed \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mnode\n\u001b[0;32m    375\u001b[0m     seed_time \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mtime\n\u001b[1;32m--> 377\u001b[0m out \u001b[39m=\u001b[39m sample_fn(seed, seed_time)\n\u001b[0;32m    378\u001b[0m out\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m (inputs\u001b[39m.\u001b[39minput_id, inputs\u001b[39m.\u001b[39mtime)\n\u001b[0;32m    380\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:276\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[1;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m     num_sampled_nodes \u001b[39m=\u001b[39m num_sampled_edges \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meither \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyg-lib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch-sparse\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m num_sampled_edges \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    280\u001b[0m     num_sampled_edges \u001b[39m=\u001b[39m remap_keys(\n\u001b[0;32m    281\u001b[0m         num_sampled_edges,\n\u001b[0;32m    282\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_edge_type,\n\u001b[0;32m    283\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "transform = T.ToUndirected()  # Add reverse edge types.\n",
    "data = OGB_MAG(root='./data', preprocess='metapath2vec', transform=transform)[0]\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "    num_neighbors=[15] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "    batch_size=128,\n",
    "    input_nodes=('paper', data['paper'].train_mask),\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, NeighborLoader works for both homogeneous and heterogeneous graphs. When operating in heterogeneous graphs, more fine-grained control over the amount of sampled neighbors of individual edge types is possible, but not necessary, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = {key: [15] * 2 for key in data.edge_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_examples = total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to('cuda:0')\n",
    "        batch_size = batch['paper'].batch_size\n",
    "        out = model(batch.x_dict, batch.edge_index_dict)\n",
    "        loss = F.cross_entropy(out['paper'][:batch_size],\n",
    "                               batch['paper'].y[:batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_examples += batch_size\n",
    "        total_loss += float(loss) * batch_size\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
