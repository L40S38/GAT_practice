{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT node classification with pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-08-06 00:58:52--  https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
      "Resolving linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)... 128.114.47.74\n",
      "Connecting to linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)|128.114.47.74|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 168052 (164K) [application/x-gzip]\n",
      "Saving to: 'cora.tgz'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 30%  109K 1s\n",
      "    50K .......... .......... .......... .......... .......... 60%  109K 1s\n",
      "   100K .......... .......... .......... .......... .......... 91%  110K 0s\n",
      "   150K .......... ....                                       100% 23.4M=1.4s\n",
      "\n",
      "2023-08-06 00:58:54 (120 KB/s) - 'cora.tgz' saved [168052/168052]\n",
      "\n",
      "x cora/\n",
      "x cora/README\n",
      "x cora/cora.cites\n",
      "x cora/cora.content\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\" -O cora.tgz\n",
    "!tar -xvzf cora.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"cora\"\n",
    "\n",
    "citations = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.cites\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"target\", \"source\"],\n",
    ")\n",
    "\n",
    "papers = pd.read_csv(\n",
    "    os.path.join(data_dir, \"cora.content\"),\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjectのリナンバリング \n",
    "class_idx = {name: id for id, name in enumerate(sorted(papers[\"subject\"].unique()))}\n",
    "# paperのリナンバリング\n",
    "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
    "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
    "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(papers.iloc[:, 1:-1])\n",
    "edges = np.array(citations[[\"target\",\"source\"]])\n",
    "labels = np.array(papers[\"subject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = features.shape[1]\n",
    "n_classes = len(np.unique(labels))\n",
    "n_nodes = features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.from_numpy(features).float()\n",
    "edges = torch.from_numpy(edges)\n",
    "labels = torch.from_numpy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array([i for i in range(n_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean = [True] * train_length + [False] * (n_nodes-train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  ..., False, False, False])"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データセットの分割\n",
    "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.5, stratify=labels)\n",
    "train_length = int(0.5*n_nodes)\n",
    "np.random.shuffle(boolean)\n",
    "indices_bool = torch.from_numpy(np.array(boolean))\n",
    "indices_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのクラス\n",
    "class CoraDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CoraDataset(train_features,train_labels)\n",
    "test_dataset = CoraDataset(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Graph Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Attention Layer\n",
    "class GraphAttention(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2):\n",
    "        super(GraphAttention, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        self.a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        torch.nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "    def forward(self, inputs, edges):\n",
    "        # 線形変換\n",
    "        #print(f\"inputs.size():{inputs.size()},self.W.size():{self.W.size()}\")\n",
    "        z = torch.mm(inputs,self.W)\n",
    "        #print(z.shape)\n",
    "\n",
    "        # e_ijの計算\n",
    "        edges_new_axis = edges.reshape(edges.shape[0],edges.shape[1],-1)\n",
    "        edges_expand = edges_new_axis.expand(edges.shape[0],edges.shape[1],z.shape[1])\n",
    "        z_new_axis = z.reshape(z.shape[0],-1,z.shape[1])\n",
    "        z_expand = z_new_axis.expand(z.shape[0],edges.shape[1],z.shape[1])\n",
    "        features_previous_concat = torch.gather(z_expand,0,edges_expand)\n",
    "        #print(f\"features_previous_concat.size():{features_previous_concat.size()}\")\n",
    "        features_concat = features_previous_concat.reshape(edges.shape[0],-1)\n",
    "        #print(features_concat.shape)\n",
    "        attention_score = leakyrelu(torch.mm(features_concat,a))\n",
    "        #print(f\"attention_score.size():{attention_score.size()}\")\n",
    "\n",
    "        # 正規化\n",
    "        E = torch.tensor([np.where(edges[:,0]==i,1,0) for i in range(n_nodes)]).float()\n",
    "        attention_score_sum_expand = torch.mm(torch.transpose(E,1,0),torch.mm(E,torch.exp(attention_score)))\n",
    "        attention_score_norm = attention_score/attention_score_sum_expand\n",
    "        #print(f\"attention_score_noem.size():{attention_score_norm.size()}\")\n",
    "\n",
    "        # z_jの更新\n",
    "        to_renew_z = attention_score_norm * features_previous_concat[:,1::2,:].reshape(-1,out_features)\n",
    "        #print(f\"to_renew_z.size():{to_renew_z.size()}\")\n",
    "        D = torch.tensor([np.where(edges[:,1]==j,1,0) for j in range(n_nodes)]).float()\n",
    "        #print(f\"D.size():{D.size()}\")\n",
    "        out = z + torch.matmul(D,to_renew_z)\n",
    "        #print(f\"out.size() of {self.__class__.__name__}:{out.size()}\")\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Graph Attention Layer\n",
    "class MultiHeadGraphAttention(nn.Module):\n",
    "    def __init__(self, in_features, n_hidden, n_heads, merge_type=\"concat\", dropout=0.6, alpha=0.2):\n",
    "        super(MultiHeadGraphAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.heads = nn.ModuleList([GraphAttention(in_features, n_hidden, dropout=dropout, alpha=alpha) for _ in range(n_heads)])\n",
    "        self.merge_type = merge_type\n",
    "\n",
    "    def forward(self, inputs, edges):\n",
    "        head_outs = [head(inputs, edges) for head in self.heads]\n",
    "        #print(f\"head_outs.size() of {self.__class__.__name__}:{torch.tensor(head_outs).size()}\")\n",
    "        if self.merge_type == \"concat\":\n",
    "            out = torch.cat(head_outs, dim=1)\n",
    "        else:\n",
    "            out =  torch.mean(torch.stack(head_outs), dim=0)\n",
    "        #print(f\"out.size() of {self.__class__.__name__}:{out.size()}\")\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Attention Network\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, n_hidden, n_heads, dropout=0.6, alpha=0.2):\n",
    "        super(GAT, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_classes = n_classes\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "        self.preprocess = nn.Linear(n_features, n_hidden * n_heads)\n",
    "        self.relu = F.relu\n",
    "        self.attentions = nn.ModuleList([MultiHeadGraphAttention(n_hidden*n_heads, n_hidden, n_heads, dropout=dropout, alpha=alpha) for _ in range(n_heads)])\n",
    "        #self.out_att = GraphAttention(n_hidden*n_heads, n_classes, dropout=dropout, alpha=alpha)\n",
    "        self.output = nn.Linear(n_hidden * n_heads, n_classes)\n",
    "\n",
    "    def forward(self, inputs, edges):\n",
    "        x = self.preprocess(inputs)\n",
    "        x = self.relu(x)\n",
    "        for att in self.attentions:\n",
    "            x = att(x, edges) + x\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "n_hidden = 8\n",
    "n_heads = 3\n",
    "model = GAT(n_features, n_classes, n_hidden, n_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "def train_model(model, optimizer, criterion, indices, data_length, features, labels, edges):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    output = model(features, edges)\n",
    "    loss = criterion(output[indices], labels[indices])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item() * features.size(0)\n",
    "    pred = output[indices].argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(labels[indices].view_as(pred)).sum().item()\n",
    "    return total_loss / data_length, correct / data_length\n",
    "\n",
    "# モデルの評価\n",
    "def evaluate_model(model, criterion, indices, data_length, features, labels, edges):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        output = model(features, edges)\n",
    "        loss = criterion(output[indices], labels[indices])\n",
    "        total_loss += loss.item() * features.size(0)\n",
    "        pred = output[indices].argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(labels[indices].view_as(pred)).sum().item()\n",
    "\n",
    "    return total_loss / data_length, correct / data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数と最適化手法の定義\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習と評価\n",
    "n_epochs = 100\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "GAT                                      --\n",
       "├─Linear: 1-1                            34,416\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─MultiHeadGraphAttention: 2-1      --\n",
       "│    │    └─ModuleList: 3-1              --\n",
       "│    │    │    └─GraphAttention: 4-1     208\n",
       "│    │    │    └─GraphAttention: 4-2     208\n",
       "│    │    │    └─GraphAttention: 4-3     208\n",
       "│    └─MultiHeadGraphAttention: 2-2      --\n",
       "│    │    └─ModuleList: 3-2              --\n",
       "│    │    │    └─GraphAttention: 4-4     208\n",
       "│    │    │    └─GraphAttention: 4-5     208\n",
       "│    │    │    └─GraphAttention: 4-6     208\n",
       "│    └─MultiHeadGraphAttention: 2-3      --\n",
       "│    │    └─ModuleList: 3-3              --\n",
       "│    │    │    └─GraphAttention: 4-7     208\n",
       "│    │    │    └─GraphAttention: 4-8     208\n",
       "│    │    │    └─GraphAttention: 4-9     208\n",
       "├─Linear: 1-3                            175\n",
       "=================================================================\n",
       "Total params: 36,463\n",
       "Trainable params: 36,463\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model=model,depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 1/100, Train Loss: 4.0059, Test Loss: 3.7955, Test Accuracy: 0.4261\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 2/100, Train Loss: 3.8300, Test Loss: 3.4665, Test Accuracy: 0.6765\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 3/100, Train Loss: 3.7310, Test Loss: 3.0086, Test Accuracy: 0.7356\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 4/100, Train Loss: 3.6193, Test Loss: 2.5793, Test Accuracy: 0.7378\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 5/100, Train Loss: 3.5853, Test Loss: 2.2528, Test Accuracy: 0.7585\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 6/100, Train Loss: 3.4556, Test Loss: 2.0721, Test Accuracy: 0.7836\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 7/100, Train Loss: 3.3199, Test Loss: 2.0055, Test Accuracy: 0.8161\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 8/100, Train Loss: 3.2358, Test Loss: 1.9189, Test Accuracy: 0.8449\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 9/100, Train Loss: 3.1826, Test Loss: 1.8755, Test Accuracy: 0.8589\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 10/100, Train Loss: 3.1223, Test Loss: 1.8073, Test Accuracy: 0.8545\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 11/100, Train Loss: 3.0780, Test Loss: 1.7413, Test Accuracy: 0.8626\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 12/100, Train Loss: 3.0673, Test Loss: 1.6521, Test Accuracy: 0.8589\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 13/100, Train Loss: 3.0062, Test Loss: 1.5419, Test Accuracy: 0.8560\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 14/100, Train Loss: 3.0024, Test Loss: 1.4038, Test Accuracy: 0.8456\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 15/100, Train Loss: 2.9953, Test Loss: 1.2220, Test Accuracy: 0.8479\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "Epoch 16/100, Train Loss: 2.9472, Test Loss: 1.0229, Test Accuracy: 0.8516\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "out.size() of MultiHeadGraphAttention:torch.Size([2708, 24])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n",
      "attention_score_noem.size():torch.Size([5429, 1])\n",
      "to_renew_z.size():torch.Size([5429, 8])\n",
      "D.size():torch.Size([2708, 5429])\n",
      "out.size() of GraphAttention:torch.Size([2708, 8])\n",
      "inputs.size():torch.Size([2708, 24]),self.W.size():torch.Size([24, 8])\n",
      "torch.Size([2708, 8])\n",
      "features_previous_concat.size():torch.Size([5429, 2, 8])\n",
      "attention_score.size():torch.Size([5429, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\gat_node_classification_pytorch.ipynb Cell 29\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train_model(model, optimizer, criterion, indices, features, labels, edges)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate_model(model, criterion, (indices\u001b[39m==\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), features, labels, edges)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mn_epochs\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\gat_node_classification_pytorch.ipynb Cell 29\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m#for features, labels in data_loader:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m#    features, labels = features.to(device), labels.to(device)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#    pred = output.argmax(dim=1, keepdim=True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m#    correct += pred.eq(labels.view_as(pred)).sum().item()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     features, labels \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     output \u001b[39m=\u001b[39m model(features, edges)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output[indices], labels[indices])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m features\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\gat_node_classification_pytorch.ipynb Cell 29\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m att \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattentions:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m att(x, edges) \u001b[39m+\u001b[39m x\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(x)\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\gat_node_classification_pytorch.ipynb Cell 29\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, edges):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     head_outs \u001b[39m=\u001b[39m [head(inputs, edges) \u001b[39mfor\u001b[39;00m head \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#print(f\"head_outs.size() of {self.__class__.__name__}:{torch.tensor(head_outs).size()}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\gat_node_classification_pytorch.ipynb Cell 29\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, edges):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     head_outs \u001b[39m=\u001b[39m [head(inputs, edges) \u001b[39mfor\u001b[39;00m head \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#print(f\"head_outs.size() of {self.__class__.__name__}:{torch.tensor(head_outs).size()}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\NEC-PCuser\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\NEC-PCuser\\OneDrive\\デスクトップ\\趣味開発用\\GAT_practice\\gat_node_classification_pytorch.ipynb Cell 29\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mattention_score.size():\u001b[39m\u001b[39m{\u001b[39;00mattention_score\u001b[39m.\u001b[39msize()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# 正規化\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m E \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([np\u001b[39m.\u001b[39;49mwhere(edges[:,\u001b[39m0\u001b[39;49m]\u001b[39m==\u001b[39;49mi,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(n_nodes)])\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m attention_score_sum_expand \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmm(torch\u001b[39m.\u001b[39mtranspose(E,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m),torch\u001b[39m.\u001b[39mmm(E,torch\u001b[39m.\u001b[39mexp(attention_score)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NEC-PCuser/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/%E8%B6%A3%E5%91%B3%E9%96%8B%E7%99%BA%E7%94%A8/GAT_practice/gat_node_classification_pytorch.ipynb#Y223sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m attention_score_norm \u001b[39m=\u001b[39m attention_score\u001b[39m/\u001b[39mattention_score_sum_expand\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "t_delta = datetime.timedelta(hours=9)\n",
    "JST = datetime.timezone(t_delta, 'JST')\n",
    "now = datetime.datetime.now(JST)\n",
    "writer = SummaryWriter(log_dir=f\"./logs/{now:%Y%m%d%H%M}\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_accuracy  = train_model(model, optimizer, criterion, indices, train_length, features, labels, edges)\n",
    "    test_loss, test_accuracy = evaluate_model(model, criterion, (indices==False), n_nodes-train_length, features, labels, edges)\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    writer.add_scalar(\"train/loss\",train_loss,epoch)\n",
    "    writer.add_scalar(\"train/accuracy\",train_accuracy,epoch)\n",
    "    writer.add_scalar(\"test/loss\",test_loss,epoch)\n",
    "    writer.add_scalar(\"test/accuracy\",test_accuracy,epoch)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=\"./logs/hogehoge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Attention Layerの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2708, 1433]), torch.Size([5429, 2]), torch.Size([2708]))"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape,edges.shape,labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0: 線形変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1433, 8])"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = n_features\n",
    "out_features = n_hidden\n",
    "W = torch.randn(size=(in_features, out_features))\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 8])"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.mm(features,W)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: $e_{ij}$の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[   0,    0,    0,  ...,    0,    0,    0],\n",
       "          [  21,   21,   21,  ...,   21,   21,   21]],\n",
       " \n",
       "         [[   0,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 905,  905,  905,  ...,  905,  905,  905]],\n",
       " \n",
       "         [[   0,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 906,  906,  906,  ...,  906,  906,  906]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1874, 1874, 1874,  ..., 1874, 1874, 1874],\n",
       "          [2586, 2586, 2586,  ..., 2586, 2586, 2586]],\n",
       " \n",
       "         [[1876, 1876, 1876,  ..., 1876, 1876, 1876],\n",
       "          [1874, 1874, 1874,  ..., 1874, 1874, 1874]],\n",
       " \n",
       "         [[1897, 1897, 1897,  ..., 1897, 1897, 1897],\n",
       "          [2707, 2707, 2707,  ..., 2707, 2707, 2707]]]),\n",
       " torch.Size([5429, 2, 8]))"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_new_axis = edges.reshape(edges.shape[0],edges.shape[1],-1)\n",
    "edges_expand = edges_new_axis.expand(edges.shape[0],edges.shape[1],z.shape[1])\n",
    "edges_expand,edges_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.9098,  0.9079,  0.9501,  ..., 10.9173,  2.3840, -1.4820],\n",
       "          [ 1.9098,  0.9079,  0.9501,  ..., 10.9173,  2.3840, -1.4820]],\n",
       " \n",
       "         [[-3.4538, -4.3552, -3.0108,  ..., -2.4590, -0.3970, -1.2268],\n",
       "          [-3.4538, -4.3552, -3.0108,  ..., -2.4590, -0.3970, -1.2268]],\n",
       " \n",
       "         [[ 6.3808,  0.3100, -0.9094,  ..., -2.3816, -4.8970,  0.5370],\n",
       "          [ 6.3808,  0.3100, -0.9094,  ..., -2.3816, -4.8970,  0.5370]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.5645, -2.1831, -3.7584,  ..., -7.9192, -1.1197,  3.4378],\n",
       "          [ 2.5645, -2.1831, -3.7584,  ..., -7.9192, -1.1197,  3.4378]],\n",
       " \n",
       "         [[ 4.8376, -3.3433, -1.5954,  ...,  0.3057, -4.9777, -0.2487],\n",
       "          [ 4.8376, -3.3433, -1.5954,  ...,  0.3057, -4.9777, -0.2487]],\n",
       " \n",
       "         [[-9.4363,  1.1044,  6.1770,  ..., -5.2679,  7.6996, -0.5346],\n",
       "          [-9.4363,  1.1044,  6.1770,  ..., -5.2679,  7.6996, -0.5346]]]),\n",
       " torch.Size([2708, 2, 8]))"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_new_axis = z.reshape(z.shape[0],-1,z.shape[1])\n",
    "z_expand = z_new_axis.expand(z.shape[0],edges.shape[1],z.shape[1])\n",
    "z_expand, z_expand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$features\\_previous\\_concat[i][j][k] = z\\_expand[edges\\_expand[i][j][k]][j][k]$\n",
    "\n",
    "$features\\_concat[i] = [features\\_previous\\_concat[i][0] || features\\_previous\\_concat[i][1]] = [z[edges[0]] || z[edges[1]]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.9098e+00,  9.0787e-01,  9.5011e-01,  ...,  1.0917e+01,\n",
       "           2.3840e+00, -1.4820e+00],\n",
       "         [-1.1673e-01,  8.3575e-01,  2.2723e+00,  ..., -3.6076e+00,\n",
       "          -2.7866e-01, -7.8429e-01]],\n",
       "\n",
       "        [[ 1.9098e+00,  9.0787e-01,  9.5011e-01,  ...,  1.0917e+01,\n",
       "           2.3840e+00, -1.4820e+00],\n",
       "         [ 1.1090e+00,  1.9547e+00, -1.0038e+00,  ...,  3.1264e+00,\n",
       "          -3.6850e-01,  1.0583e+00]],\n",
       "\n",
       "        [[ 1.9098e+00,  9.0787e-01,  9.5011e-01,  ...,  1.0917e+01,\n",
       "           2.3840e+00, -1.4820e+00],\n",
       "         [ 1.2936e-02,  3.3463e+00,  3.0718e+00,  ...,  6.8319e+00,\n",
       "          -1.5667e+00, -1.2071e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.8806e+00,  5.4618e-01, -8.9918e+00,  ..., -8.0656e+00,\n",
       "          -7.9111e-01,  2.9114e+00],\n",
       "         [-7.5609e-02,  1.9678e-01, -9.0859e+00,  ..., -3.0945e+00,\n",
       "           1.9150e+00, -3.9001e+00]],\n",
       "\n",
       "        [[ 4.2383e-01,  4.7445e-01, -2.5989e+00,  ..., -7.9082e+00,\n",
       "           2.1607e+00,  2.9065e+00],\n",
       "         [ 2.8806e+00,  5.4618e-01, -8.9918e+00,  ..., -8.0656e+00,\n",
       "          -7.9111e-01,  2.9114e+00]],\n",
       "\n",
       "        [[-5.7951e+00,  6.1270e+00, -1.1592e+00,  ...,  3.7956e+00,\n",
       "          -1.3093e+01,  4.3491e-01],\n",
       "         [-9.4363e+00,  1.1044e+00,  6.1770e+00,  ..., -5.2679e+00,\n",
       "           7.6996e+00, -5.3459e-01]]])"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_previous_concat = torch.gather(z_expand,0,edges_expand)\n",
    "features_previous_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5429, 16])"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_concat = features_previous_concat.reshape(edges.shape[0],-1)\n",
    "features_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$LeakyReLU(x)=max(0,x)+negative\\_slope∗min(0,x)$\n",
    "\n",
    "Reference:https://pytorch.org/docs/stable/generated/torch.nn.functional.leaky_relu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1de8c8a8430>]"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "negative_slope = 0.01 #default value\n",
    "X = np.arange(-0.5,0.5,0.01)\n",
    "LeakyReLU = np.maximum(X,0) + negative_slope*np.minimum(X,0)\n",
    "plt.plot(X,LeakyReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6.4770],\n",
       "         [ 0.7722],\n",
       "         [-1.4811],\n",
       "         ...,\n",
       "         [ 7.4192],\n",
       "         [11.7632],\n",
       "         [ 9.1880]]),\n",
       " torch.Size([5429, 1]))"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LeakyReluの適用\n",
    "a = torch.randn(size=(2*out_features, 1))\n",
    "alpha = 0.2\n",
    "leakyrelu = nn.LeakyReLU(alpha)\n",
    "attention_score = leakyrelu(torch.mm(features_concat,a))\n",
    "attention_score, attention_score.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: 正規化\n",
    "\n",
    "$edges[k]=[i,j]$のとき$attention\\_score[k] = e_{ij}$\n",
    "\n",
    "$E_{kl} = \n",
    "  \\begin{cases}\n",
    "    1 & \\quad \\textrm{if } edges[k][0]==l \\\\\n",
    "    0                 & \\quad \\textrm{otherwise}\n",
    "  \\end{cases}\n",
    "$\n",
    "\n",
    "$e\\_sum_i = \\sum_j exp(e_{ij}) = E exp(e_{ij})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([2708, 5429]))"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = torch.tensor([np.where(edges[:,0]==i,1,0) for i in range(n_nodes)]).float()\n",
    "E, E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.6907e+13],\n",
       "         [2.8349e-01],\n",
       "         [1.1490e+17],\n",
       "         ...,\n",
       "         [0.0000e+00],\n",
       "         [0.0000e+00],\n",
       "         [0.0000e+00]]),\n",
       " torch.Size([2708, 1]))"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score_sum = torch.matmul(E,torch.exp(attention_score))\n",
    "attention_score_sum, attention_score_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.6907e+13],\n",
       "         [3.6907e+13],\n",
       "         [3.6907e+13],\n",
       "         ...,\n",
       "         [1.6677e+03],\n",
       "         [1.2844e+05],\n",
       "         [9.7789e+03]]),\n",
       " torch.Size([5429, 1]))"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score_sum_expand = torch.matmul(torch.transpose(E,1,0),attention_score_sum)\n",
    "attention_score_sum_expand, attention_score_sum_expand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.7550e-13],\n",
       "         [ 2.0923e-14],\n",
       "         [-4.0130e-14],\n",
       "         ...,\n",
       "         [ 4.4487e-03],\n",
       "         [ 9.1585e-05],\n",
       "         [ 9.3957e-04]]),\n",
       " torch.Size([5429, 1]))"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score_norm = attention_score/attention_score_sum_expand\n",
    "attention_score_norm, attention_score_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: $z_j$ の更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$to\\_renew\\_z_{e_{ij}} = norm(e_{ij})*\\boldsymbol{h}_j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.0486e-14,  1.4667e-13,  3.9879e-13,  ..., -6.3312e-13,\n",
       "          -4.8903e-14, -1.3764e-13],\n",
       "         [ 2.3204e-14,  4.0899e-14, -2.1002e-14,  ...,  6.5414e-14,\n",
       "          -7.7103e-15,  2.2144e-14],\n",
       "         [-5.1910e-16, -1.3429e-13, -1.2327e-13,  ..., -2.7416e-13,\n",
       "           6.2873e-14,  4.8442e-14],\n",
       "         ...,\n",
       "         [-3.3636e-04,  8.7543e-04, -4.0421e-02,  ..., -1.3767e-02,\n",
       "           8.5191e-03, -1.7350e-02],\n",
       "         [ 2.6382e-04,  5.0022e-05, -8.2351e-04,  ..., -7.3869e-04,\n",
       "          -7.2454e-05,  2.6664e-04],\n",
       "         [-8.8660e-03,  1.0377e-03,  5.8038e-03,  ..., -4.9496e-03,\n",
       "           7.2343e-03, -5.0229e-04]]),\n",
       " torch.Size([5429, 8]))"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_renew_z = attention_score_norm * features_previous_concat[:,1::2,:].reshape(-1,out_features)\n",
    "to_renew_z, to_renew_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.]]),\n",
       " torch.Size([2708, 5429]))"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.tensor([np.where(edges[:,1]==j,1,0) for j in range(n_nodes)]).float()\n",
    "D, D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.9098,   0.9079,   0.9501,  ...,  10.9173,   2.3840,  -1.4820],\n",
       "         [ -3.4538,  -4.3552,  -3.0108,  ...,  -2.4590,  -0.3970,  -1.2268],\n",
       "         [  6.3808,   0.3100,  -0.9094,  ...,  -2.3816,  -4.8970,   0.5370],\n",
       "         ...,\n",
       "         [  2.5645,  -2.1831,  -3.7584,  ...,  -7.9192,  -1.1197,   3.4378],\n",
       "         [  2.2302,  -1.5413,  -0.7355,  ...,   0.1409,  -2.2948,  -0.1147],\n",
       "         [-12.0314,   1.4081,   7.8758,  ...,  -6.7166,   9.8171,  -0.6816]]),\n",
       " torch.Size([2708, 8]))"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = z + torch.matmul(D,to_renew_z)\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Attention Layerのまとめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形変換\n",
    "z = torch.mm(features,W)\n",
    "\n",
    "# e_ijの計算\n",
    "edges_new_axis = edges.reshape(edges.shape[0],edges.shape[1],-1)\n",
    "edges_expand = edges_new_axis.expand(edges.shape[0],edges.shape[1],z.shape[1])\n",
    "z_new_axis = z.reshape(z.shape[0],-1,z.shape[1])\n",
    "z_expand = z_new_axis.expand(z.shape[0],edges.shape[1],z.shape[1])\n",
    "features_previous_concat = torch.gather(z_expand,0,edges_expand)\n",
    "features_concat = features_previous_concat.reshape(edges.shape[0],-1)\n",
    "attention_score = leakyrelu(torch.mm(features_concat,a))\n",
    "\n",
    "# 正規化\n",
    "E = torch.tensor([np.where(edges[:,0]==i,1,0) for i in range(n_nodes)]).float()\n",
    "attention_score_sum_expand = torch.mm(torch.transpose(E,1,0),torch.mm(E,torch.exp(attention_score)))\n",
    "attention_score_norm = attention_score/attention_score_sum_expand\n",
    "\n",
    "# z_jの更新\n",
    "to_renew_z = attention_score_norm * features_previous_concat[:,1::2,:].reshape(edges.shape[0],-1)\n",
    "D = torch.tensor([np.where(edges[:,1]==j,1,0) for j in range(n_nodes)]).float()\n",
    "out = z + torch.matmul(D,to_renew_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 8])"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.catについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    0,     1,     2,  ...,     5,     6,     7],\n",
       "         [    8,     9,    10,  ...,    13,    14,    15],\n",
       "         [   16,    17,    18,  ...,    21,    22,    23],\n",
       "         ...,\n",
       "         [21640, 21641, 21642,  ..., 21645, 21646, 21647],\n",
       "         [21648, 21649, 21650,  ..., 21653, 21654, 21655],\n",
       "         [21656, 21657, 21658,  ..., 21661, 21662, 21663]]),\n",
       " tensor([[    0,     1,     2,  ...,     5,     6,     7],\n",
       "         [    8,     9,    10,  ...,    13,    14,    15],\n",
       "         [   16,    17,    18,  ...,    21,    22,    23],\n",
       "         ...,\n",
       "         [21640, 21641, 21642,  ..., 21645, 21646, 21647],\n",
       "         [21648, 21649, 21650,  ..., 21653, 21654, 21655],\n",
       "         [21656, 21657, 21658,  ..., 21661, 21662, 21663]]),\n",
       " tensor([[    0,     1,     2,  ...,     5,     6,     7],\n",
       "         [    8,     9,    10,  ...,    13,    14,    15],\n",
       "         [   16,    17,    18,  ...,    21,    22,    23],\n",
       "         ...,\n",
       "         [21640, 21641, 21642,  ..., 21645, 21646, 21647],\n",
       "         [21648, 21649, 21650,  ..., 21653, 21654, 21655],\n",
       "         [21656, 21657, 21658,  ..., 21661, 21662, 21663]])]"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_out = [torch.arange(0,2708*8).reshape(2708,8) for _ in range(n_heads)]\n",
    "head_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     1,     2,  ...,     5,     6,     7],\n",
       "         [    8,     9,    10,  ...,    13,    14,    15],\n",
       "         [   16,    17,    18,  ...,    21,    22,    23],\n",
       "         ...,\n",
       "         [21640, 21641, 21642,  ..., 21645, 21646, 21647],\n",
       "         [21648, 21649, 21650,  ..., 21653, 21654, 21655],\n",
       "         [21656, 21657, 21658,  ..., 21661, 21662, 21663]]),\n",
       " tensor([[    0,     1,     2,  ...,     5,     6,     7],\n",
       "         [    8,     9,    10,  ...,    13,    14,    15],\n",
       "         [   16,    17,    18,  ...,    21,    22,    23],\n",
       "         ...,\n",
       "         [21640, 21641, 21642,  ..., 21645, 21646, 21647],\n",
       "         [21648, 21649, 21650,  ..., 21653, 21654, 21655],\n",
       "         [21656, 21657, 21658,  ..., 21661, 21662, 21663]]))"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(head_out,dim=1),torch.cat(head_out,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2708, 24]), torch.Size([8124, 8]))"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(head_out,dim=1).size(),torch.cat(head_out,dim=0).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
