{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/L40S38/GAT_practice/blob/main/gat_node_classification_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ABqwGnrnoLy"
      },
      "source": [
        "# GAT node classification with pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjlwDpbfnoL9"
      },
      "source": [
        "## import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "kZHks0TvnoL-",
        "outputId": "01acc797-458c-4ff2-b7f1-6cd85629b628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練に際して、可能であればGPU（cuda）を設定します。GPUが搭載されていない場合はCPUを使用します\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "metadata": {
        "id": "7RMy0hRzrcZG",
        "outputId": "cc7f54d6-13be-43f9-b1fe-f31db270d1d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda:0 device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sTH0rO7noMB"
      },
      "source": [
        "## download Cora dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "VgGXa4VcnoMC",
        "outputId": "be1a2428-8c6b-49fc-f557-9fd3c7f7b21f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-05 18:01:25--  https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
            "Resolving linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)... 128.114.47.74\n",
            "Connecting to linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)|128.114.47.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168052 (164K) [application/x-gzip]\n",
            "Saving to: ‘cora.tgz’\n",
            "\n",
            "cora.tgz            100%[===================>] 164.11K   247KB/s    in 0.7s    \n",
            "\n",
            "2023-08-05 18:01:27 (247 KB/s) - ‘cora.tgz’ saved [168052/168052]\n",
            "\n",
            "cora/\n",
            "cora/README\n",
            "cora/cora.cites\n",
            "cora/cora.content\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\" -O cora.tgz\n",
        "!tar -xvzf cora.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "laQ-wRnynoMF"
      },
      "outputs": [],
      "source": [
        "data_dir = \"cora\"\n",
        "\n",
        "citations = pd.read_csv(\n",
        "    os.path.join(data_dir, \"cora.cites\"),\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"target\", \"source\"],\n",
        ")\n",
        "\n",
        "papers = pd.read_csv(\n",
        "    os.path.join(data_dir, \"cora.content\"),\n",
        "    sep=\"\\t\",\n",
        "    header=None,\n",
        "    names=[\"paper_id\"] + [f\"term_{idx}\" for idx in range(1433)] + [\"subject\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "rXxW2ebTnoMH"
      },
      "outputs": [],
      "source": [
        "# subjectのリナンバリング\n",
        "class_idx = {name: id for id, name in enumerate(sorted(papers[\"subject\"].unique()))}\n",
        "# paperのリナンバリング\n",
        "paper_idx = {name: idx for idx, name in enumerate(sorted(papers[\"paper_id\"].unique()))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "ZBcvoq2qnoMK"
      },
      "outputs": [],
      "source": [
        "papers[\"paper_id\"] = papers[\"paper_id\"].apply(lambda name: paper_idx[name])\n",
        "citations[\"source\"] = citations[\"source\"].apply(lambda name: paper_idx[name])\n",
        "citations[\"target\"] = citations[\"target\"].apply(lambda name: paper_idx[name])\n",
        "papers[\"subject\"] = papers[\"subject\"].apply(lambda value: class_idx[value])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "3vea2DapnoMM"
      },
      "outputs": [],
      "source": [
        "features = np.array(papers.iloc[:, 1:-1])\n",
        "edges = np.array(citations[[\"target\",\"source\"]])\n",
        "labels = np.array(papers[\"subject\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "YMUUVKJ_noMO"
      },
      "outputs": [],
      "source": [
        "n_features = features.shape[1]\n",
        "n_classes = len(np.unique(labels))\n",
        "n_nodes = features.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "XJ0uTmVynoMP"
      },
      "outputs": [],
      "source": [
        "features = torch.from_numpy(features).float()\n",
        "edges = torch.from_numpy(edges)\n",
        "labels = torch.from_numpy(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "hCktOLr1noMQ"
      },
      "outputs": [],
      "source": [
        "indices = np.array([i for i in range(n_nodes)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "idQykxQUnoMQ",
        "outputId": "aa6b7b56-e40f-42e5-a568-013f29b60779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "train_length = int(0.5*n_nodes)\n",
        "boolean = [True] * train_length + [False] * (n_nodes-train_length)\n",
        "boolean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "0QmirCGJnoMR",
        "outputId": "7bf59481-3b41-468b-f6df-72c00edf119b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False,  True,  True,  ..., False, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "#データセットの分割\n",
        "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.5, stratify=labels)\n",
        "np.random.shuffle(boolean)\n",
        "indices_bool = torch.from_numpy(np.array(boolean))\n",
        "indices_bool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ROcQdhNnoMT"
      },
      "source": [
        "## Implement Graph Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "P38CyczAnoMT"
      },
      "outputs": [],
      "source": [
        "# Graph Attention Layer\n",
        "class GraphAttention(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout=0.6, alpha=0.2):\n",
        "        super(GraphAttention, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
        "        self.a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        torch.nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
        "        torch.nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "    def forward(self, inputs, edges):\n",
        "        # 線形変換\n",
        "        #print(f\"inputs.size():{inputs.size()},self.W.size():{self.W.size()}\")\n",
        "        z = torch.mm(inputs,self.W)\n",
        "        #print(z.shape)\n",
        "\n",
        "        # e_ijの計算\n",
        "        edges_new_axis = edges.reshape(edges.size(0),edges.size(1),-1)\n",
        "        edges_expand = edges_new_axis.expand(edges.size(0),edges.size(1),z.size(1))\n",
        "        z_new_axis = z.reshape(z.size(0),-1,z.size(1))\n",
        "        z_expand = z_new_axis.expand(z.size(0),edges.size(1),z.size(1))\n",
        "        features_previous_concat = torch.gather(z_expand,0,edges_expand)\n",
        "        #print(f\"features_previous_concat.size():{features_previous_concat.size()}\")\n",
        "        features_concat = features_previous_concat.reshape(edges.size(0),-1)\n",
        "        #print(features_concat.shape)\n",
        "        attention_score = self.leakyrelu(torch.mm(features_concat,self.a))\n",
        "        #print(f\"attention_score.size():{attention_score.size()}\")\n",
        "\n",
        "        # 正規化\n",
        "        E = torch.stack([torch.where(edges[:,0]==i,1,0) for i in range(n_nodes)]).float()\n",
        "        attention_score_sum_expand = torch.mm(torch.transpose(E,1,0),torch.mm(E,torch.exp(attention_score)))\n",
        "        attention_score_norm = attention_score/attention_score_sum_expand\n",
        "        #print(f\"attention_score_noem.size():{attention_score_norm.size()}\")\n",
        "\n",
        "        # z_jの更新\n",
        "        to_renew_z = attention_score_norm * features_previous_concat[:,1::2,:].squeeze() #.reshape(-1, out_features)\n",
        "        #print(f\"to_renew_z.size():{to_renew_z.size()}\")\n",
        "        D = torch.stack([torch.where(edges[:,1]==j,1,0) for j in range(n_nodes)]).float()\n",
        "        #print(f\"D.size():{D.size()}\")\n",
        "        out = z + torch.matmul(D,to_renew_z)\n",
        "        #print(f\"out.size() of {self.__class__.__name__}:{out.size()}\")\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "TMLfr-rbnoMU"
      },
      "outputs": [],
      "source": [
        "# Multi-Head Graph Attention Layer\n",
        "class MultiHeadGraphAttention(nn.Module):\n",
        "    def __init__(self, in_features, n_hidden, n_layers, n_heads, merge_type=\"concat\", dropout=0.6, alpha=0.2):\n",
        "        super(MultiHeadGraphAttention, self).__init__()\n",
        "        self.heads = nn.ModuleList([GraphAttention(in_features, n_hidden, dropout=dropout, alpha=alpha) for _ in range(n_layers)])\n",
        "        self.merge_type = merge_type\n",
        "\n",
        "    def forward(self, inputs, edges):\n",
        "        head_outs = [head(inputs, edges) for head in self.heads]\n",
        "        #print(f\"head_outs.size() of {self.__class__.__name__}:{torch.tensor(head_outs).size()}\")\n",
        "        if self.merge_type == \"concat\":\n",
        "            out = torch.cat(head_outs, dim=1)\n",
        "        else:\n",
        "            out =  torch.mean(torch.stack(head_outs), dim=0)\n",
        "        #print(f\"out.size() of {self.__class__.__name__}:{out.size()}\")\n",
        "        return F.relu(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "a77w0YySnoMV"
      },
      "outputs": [],
      "source": [
        "# Graph Attention Network\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, n_features, n_classes, n_hidden, n_layers, n_heads, dropout=0.6, alpha=0.2):\n",
        "        super(GAT, self).__init__()\n",
        "        self.n_features = n_features\n",
        "        self.n_classes = n_classes\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout = dropout\n",
        "        self.alpha = alpha\n",
        "        self.preprocess = nn.Linear(n_features, n_hidden * n_layers)\n",
        "        self.relu = F.relu\n",
        "        self.attentions = nn.ModuleList([MultiHeadGraphAttention(n_hidden * n_layers, n_hidden, n_layers, n_heads, dropout=dropout, alpha=alpha) for _ in range(n_heads)])\n",
        "        #self.out_att = GraphAttention(n_hidden*n_heads, n_classes, dropout=dropout, alpha=alpha)\n",
        "        self.output = nn.Linear(n_hidden * n_layers, n_classes)\n",
        "\n",
        "    def forward(self, inputs, edges):\n",
        "        x = self.preprocess(inputs)\n",
        "        x = self.relu(x)\n",
        "        for att in self.attentions:\n",
        "            x = att(x, edges) + x\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.output(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "gtzcIYmYnoMW"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "n_hidden = 100\n",
        "n_heads = 8\n",
        "n_layers = 3\n",
        "model = GAT(n_features, n_classes, n_hidden, n_layers, n_heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb8bVReEnoMW"
      },
      "source": [
        "## Model Training and Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "sa5kljYMnoMX"
      },
      "outputs": [],
      "source": [
        "# モデルの学習\n",
        "def train_model(model, optimizer, criterion, indices_bool, data_length, features, labels, edges):\n",
        "    model.train()\n",
        "    features, labels, edges = features.to(device), labels.to(device), edges.to(device)\n",
        "    #features, labels = features.to(device), labels.to(device)\n",
        "    output = model(features, edges)\n",
        "    loss = criterion(output[indices_bool], labels[indices_bool])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss = loss.item() * features.size(0)\n",
        "    with torch.no_grad():\n",
        "        pred = output[indices_bool].argmax(dim=1, keepdim=True).squeeze()\n",
        "        correct = (pred==labels[indices_bool]).sum().item()\n",
        "        print(f\"Train correct:{correct}/{data_length}\")\n",
        "    #optimizer.zero_grad()\n",
        "    return total_loss / data_length, correct / data_length\n",
        "\n",
        "# モデルの評価\n",
        "def evaluate_model(model, criterion, indices_bool, data_length, features, labels, edges):\n",
        "    model.eval()\n",
        "    features, labels, edges = features.to(device), labels.to(device), edges.to(device)\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        #features, labels = features.to(device), labels.to(device)\n",
        "        output = model(features, edges)\n",
        "        loss = criterion(output[indices_bool], labels[indices_bool])\n",
        "        total_loss = loss.item() * features.size(0)\n",
        "        pred = output[indices_bool].argmax(dim=1, keepdim=True).squeeze()\n",
        "        correct = (pred==labels[indices_bool]).sum().item()\n",
        "        print(f\"Test correct:{correct}/{data_length}\")\n",
        "    return total_loss / data_length, correct / data_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "S4uwMh5anoMX"
      },
      "outputs": [],
      "source": [
        "# 損失関数と最適化手法の定義\n",
        "criterion = nn.NLLLoss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "id": "RqWFK4WenoMZ"
      },
      "outputs": [],
      "source": [
        "# モデルの学習と評価\n",
        "n_epochs = 30\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "i7n1LQybnoMZ",
        "outputId": "0e9a6548-c9cb-4fc7-d632-8771852b53fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "GAT                                           --\n",
              "├─Linear: 1-1                                 430,200\n",
              "├─ModuleList: 1-2                             --\n",
              "│    └─MultiHeadGraphAttention: 2-1           --\n",
              "│    │    └─ModuleList: 3-1                   --\n",
              "│    │    │    └─GraphAttention: 4-1          30,200\n",
              "│    │    │    └─GraphAttention: 4-2          30,200\n",
              "│    │    │    └─GraphAttention: 4-3          30,200\n",
              "│    └─MultiHeadGraphAttention: 2-2           --\n",
              "│    │    └─ModuleList: 3-2                   --\n",
              "│    │    │    └─GraphAttention: 4-4          30,200\n",
              "│    │    │    └─GraphAttention: 4-5          30,200\n",
              "│    │    │    └─GraphAttention: 4-6          30,200\n",
              "│    └─MultiHeadGraphAttention: 2-3           --\n",
              "│    │    └─ModuleList: 3-3                   --\n",
              "│    │    │    └─GraphAttention: 4-7          30,200\n",
              "│    │    │    └─GraphAttention: 4-8          30,200\n",
              "│    │    │    └─GraphAttention: 4-9          30,200\n",
              "│    └─MultiHeadGraphAttention: 2-4           --\n",
              "│    │    └─ModuleList: 3-4                   --\n",
              "│    │    │    └─GraphAttention: 4-10         30,200\n",
              "│    │    │    └─GraphAttention: 4-11         30,200\n",
              "│    │    │    └─GraphAttention: 4-12         30,200\n",
              "│    └─MultiHeadGraphAttention: 2-5           --\n",
              "│    │    └─ModuleList: 3-5                   --\n",
              "│    │    │    └─GraphAttention: 4-13         30,200\n",
              "│    │    │    └─GraphAttention: 4-14         30,200\n",
              "│    │    │    └─GraphAttention: 4-15         30,200\n",
              "│    └─MultiHeadGraphAttention: 2-6           --\n",
              "│    │    └─ModuleList: 3-6                   --\n",
              "│    │    │    └─GraphAttention: 4-16         30,200\n",
              "│    │    │    └─GraphAttention: 4-17         30,200\n",
              "│    │    │    └─GraphAttention: 4-18         30,200\n",
              "│    └─MultiHeadGraphAttention: 2-7           --\n",
              "│    │    └─ModuleList: 3-7                   --\n",
              "│    │    │    └─GraphAttention: 4-19         30,200\n",
              "│    │    │    └─GraphAttention: 4-20         30,200\n",
              "│    │    │    └─GraphAttention: 4-21         30,200\n",
              "│    └─MultiHeadGraphAttention: 2-8           --\n",
              "│    │    └─ModuleList: 3-8                   --\n",
              "│    │    │    └─GraphAttention: 4-22         30,200\n",
              "│    │    │    └─GraphAttention: 4-23         30,200\n",
              "│    │    │    └─GraphAttention: 4-24         30,200\n",
              "├─Linear: 1-3                                 2,107\n",
              "======================================================================\n",
              "Total params: 1,157,107\n",
              "Trainable params: 1,157,107\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "summary(model=model,depth=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "hP1ebzcbnoMa",
        "outputId": "5cd265c5-3c04-4754-bfcb-cb7d4359a43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-324-ba02bb0fa031>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_bool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices_bool\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-320-f4bab048dfc4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, indices_bool, data_length, features, labels, edges)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#features, labels = features.to(device), labels.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m    210\u001b[0m     def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n\u001b[1;32m    211\u001b[0m                  reduce=None, reduction: str = 'mean') -> None:\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "t_delta = datetime.timedelta(hours=9)\n",
        "JST = datetime.timezone(t_delta, 'JST')\n",
        "now = datetime.datetime.now(JST)\n",
        "writer = SummaryWriter(log_dir=f\"./logs/{now:%Y%m%d%H%M}\")\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_accuracy  = train_model(model, optimizer, criterion, indices_bool, train_length, features, labels, edges)\n",
        "    test_loss, test_accuracy = evaluate_model(model, criterion, (indices_bool==False), n_nodes-train_length, features, labels, edges)\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "    writer.add_scalar(\"train/loss\",train_loss,epoch)\n",
        "    writer.add_scalar(\"train/accuracy\",train_accuracy,epoch)\n",
        "    writer.add_scalar(\"test/loss\",test_loss,epoch)\n",
        "    writer.add_scalar(\"test/accuracy\",test_accuracy,epoch)\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def eval_check(model, device, indices_bool, features, labels, edges):\n",
        "  features, labels, edges = features.to(device), labels.to(device), edges.to(device)\n",
        "  with torch.no_grad():\n",
        "    output = model(features, edges)\n",
        "    print(output[indices_bool==False].size(),labels[indices_bool==False].size())\n",
        "\n",
        "    pred = output[indices_bool==False].argmax(dim=1, keepdim=True).squeeze()\n",
        "    correct = (pred==labels[indices_bool==False]).sum().item()\n",
        "    print(pred.size())\n",
        "    print(correct)\n",
        "    print(confusion_matrix(labels[indices_bool==False].cpu(), pred.cpu()))\n",
        "\n",
        "eval_check(model, device, indices_bool, features, labels, edges)"
      ],
      "metadata": {
        "id": "tpSkzuBdx9BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcppNvHfnoMa"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  print(\"エラー、やり直してください\")\n",
        "  pass\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboardで結果を見るときはこのコメントアウトを外す\n",
        "# %tensorboard --logdir=\"./logs/TTTT\""
      ],
      "metadata": {
        "id": "WrWJ0xrv4c8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjMAIGKknoMb"
      },
      "source": [
        "# for debug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-DZc607noMb"
      },
      "source": [
        "## Graph Attention Layerの計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ZCvJtWnoMc"
      },
      "outputs": [],
      "source": [
        "features.shape,edges.shape,labels.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7PUfiBynoMc"
      },
      "source": [
        "### 0: 線形変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHyXHKBlnoMd"
      },
      "outputs": [],
      "source": [
        "in_features = n_features\n",
        "out_features = n_hidden\n",
        "W = torch.randn(size=(in_features, out_features))\n",
        "W.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1pPnmQ7noMd"
      },
      "outputs": [],
      "source": [
        "z = torch.mm(features,W)\n",
        "z.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuNctU1DnoMe"
      },
      "source": [
        "### 1: $e_{ij}$の計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wjBLD3UnoMe"
      },
      "outputs": [],
      "source": [
        "edges_new_axis = edges.reshape(edges.shape[0],edges.shape[1],-1)\n",
        "edges_expand = edges_new_axis.expand(edges.shape[0],edges.shape[1],z.shape[1])\n",
        "edges_expand,edges_expand.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyQky-nanoMf"
      },
      "outputs": [],
      "source": [
        "z_new_axis = z.reshape(z.shape[0],-1,z.shape[1])\n",
        "z_expand = z_new_axis.expand(z.shape[0],edges.shape[1],z.shape[1])\n",
        "z_expand, z_expand.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR95iiodnoMp"
      },
      "source": [
        "$features\\_previous\\_concat[i][j][k] = z\\_expand[edges\\_expand[i][j][k]][j][k]$\n",
        "\n",
        "$features\\_concat[i] = [features\\_previous\\_concat[i][0] || features\\_previous\\_concat[i][1]] = [z[edges[0]] || z[edges[1]]]$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFvpz6E8noMp"
      },
      "outputs": [],
      "source": [
        "features_previous_concat = torch.gather(z_expand,0,edges_expand)\n",
        "features_previous_concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voQIqg3tnoMq"
      },
      "outputs": [],
      "source": [
        "features_concat = features_previous_concat.reshape(edges.shape[0],-1)\n",
        "features_concat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paz60--BnoMq"
      },
      "source": [
        "$LeakyReLU(x)=max(0,x)+negative\\_slope∗min(0,x)$\n",
        "\n",
        "Reference:https://pytorch.org/docs/stable/generated/torch.nn.functional.leaky_relu.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wx-Dik_noMr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "negative_slope = 0.01 #default value\n",
        "X = np.arange(-0.5,0.5,0.01)\n",
        "LeakyReLU = np.maximum(X,0) + negative_slope*np.minimum(X,0)\n",
        "plt.plot(X,LeakyReLU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh1X7FZ8noMr"
      },
      "outputs": [],
      "source": [
        "#LeakyReluの適用\n",
        "a = torch.randn(size=(2*out_features, 1))\n",
        "alpha = 0.2\n",
        "leakyrelu = nn.LeakyReLU(alpha)\n",
        "attention_score = leakyrelu(torch.mm(features_concat,a))\n",
        "attention_score, attention_score.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKxUn-SAnoMs"
      },
      "source": [
        "### 2: 正規化\n",
        "\n",
        "$edges[k]=[i,j]$のとき$attention\\_score[k] = e_{ij}$\n",
        "\n",
        "$E_{kl} =\n",
        "  \\begin{cases}\n",
        "    1 & \\quad \\textrm{if } edges[k][0]==l \\\\\n",
        "    0                 & \\quad \\textrm{otherwise}\n",
        "  \\end{cases}\n",
        "$\n",
        "\n",
        "$e\\_sum_i = \\sum_j exp(e_{ij}) = E exp(e_{ij})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9qqB3_ZnoMs"
      },
      "outputs": [],
      "source": [
        "E = torch.stack([torch.where(edges[:,0]==i,1,0) for i in range(n_nodes)]).float()\n",
        "E, E.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xrNdM68noMt"
      },
      "outputs": [],
      "source": [
        "attention_score_sum = torch.matmul(E,torch.exp(attention_score))\n",
        "attention_score_sum, attention_score_sum.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HR9iu2tnoMu"
      },
      "outputs": [],
      "source": [
        "attention_score_sum_expand = torch.matmul(torch.transpose(E,1,0),attention_score_sum)\n",
        "attention_score_sum_expand, attention_score_sum_expand.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaabtEFfnoMu"
      },
      "outputs": [],
      "source": [
        "attention_score_norm = attention_score/attention_score_sum_expand\n",
        "attention_score_norm, attention_score_norm.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTMt7gignoMv"
      },
      "source": [
        "### 3: $z_j$ の更新"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpCK-AR9noMv"
      },
      "source": [
        "$to\\_renew\\_z_{e_{ij}} = norm(e_{ij})*\\boldsymbol{h}_j$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zv3lN_rnoMw"
      },
      "outputs": [],
      "source": [
        "to_renew_z = attention_score_norm * features_previous_concat[:,1::2,:].reshape(-1,out_features)\n",
        "to_renew_z, to_renew_z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GLfnOthnoMx"
      },
      "outputs": [],
      "source": [
        "D = torch.stack([torch.where(edges[:,1]==j,1,0) for j in range(n_nodes)]).float()\n",
        "D, D.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqNpqQpwnoMx"
      },
      "outputs": [],
      "source": [
        "out = z + torch.matmul(D,to_renew_z)\n",
        "out, out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEePLPMqnoMy"
      },
      "source": [
        "## Graph Attention Layerのまとめ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly1Ukr0gnoMy"
      },
      "outputs": [],
      "source": [
        "# 線形変換\n",
        "z = torch.mm(features,W)\n",
        "\n",
        "# e_ijの計算\n",
        "edges_new_axis = edges.reshape(edges.shape[0],edges.shape[1],-1)\n",
        "edges_expand = edges_new_axis.expand(edges.shape[0],edges.shape[1],z.shape[1])\n",
        "z_new_axis = z.reshape(z.shape[0],-1,z.shape[1])\n",
        "z_expand = z_new_axis.expand(z.shape[0],edges.shape[1],z.shape[1])\n",
        "features_previous_concat = torch.gather(z_expand,0,edges_expand)\n",
        "features_concat = features_previous_concat.reshape(edges.shape[0],-1)\n",
        "attention_score = leakyrelu(torch.mm(features_concat,a))\n",
        "\n",
        "# 正規化\n",
        "E = torch.stack([torch.where(edges[:,0]==i,1,0) for i in range(n_nodes)]).float()\n",
        "attention_score_sum_expand = torch.mm(torch.transpose(E,1,0),torch.mm(E,torch.exp(attention_score)))\n",
        "attention_score_norm = attention_score/attention_score_sum_expand\n",
        "\n",
        "# z_jの更新\n",
        "to_renew_z = attention_score_norm * features_previous_concat[:,1::2,:].reshape(edges.shape[0],-1)\n",
        "D = torch.stack([torch.where(edges[:,1]==j,1,0) for j in range(n_nodes)]).float()\n",
        "out = z + torch.matmul(D,to_renew_z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPTCEUk2noMz"
      },
      "outputs": [],
      "source": [
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTpq0G3FnoM0"
      },
      "source": [
        "## torch.catについて"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmHI9TgFnoM1"
      },
      "outputs": [],
      "source": [
        "head_out = [torch.arange(0,2708*8).reshape(2708,8) for _ in range(n_heads)]\n",
        "head_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thJEt-ELnoM2"
      },
      "outputs": [],
      "source": [
        "torch.cat(head_out,dim=1),torch.cat(head_out,dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNbf2YvfnoM2"
      },
      "outputs": [],
      "source": [
        "torch.cat(head_out,dim=1).size(),torch.cat(head_out,dim=0).size()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}